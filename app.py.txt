# app.py — TimeSculpt (consolidated, single-file build)

import os, json, math, random, datetime as dt, sqlite3, logging
from typing import Dict, List, Tuple, Optional

import numpy as np
import pandas as pd
import altair as alt
import streamlit as st

# Optional deps for lens upload
try:
    import docx  # python-docx
except Exception:
    docx = None
try:
    import PyPDF2
except Exception:
    PyPDF2 = None

# Optional: bcrypt for PIN hashing
try:
    import bcrypt
except Exception:
    bcrypt = None

# Optional AI
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
try:
    from openai import OpenAI
    _openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None
except Exception:
    _openai_client = None

# =========================
# App Config & Visual Style
# =========================

st.set_page_config(page_title="TimeSculpt", layout="wide")
st.markdown("""
<style>
/* Subtle dark theme polish */
html, body, [class^="css"]  {
  background-color: #0D0D10 !important;
}
h1, h2, h3 { color:#E0C36D; font-family: ui-serif, Georgia, serif; }
section.main > div { padding-top: 0.25rem !important; }
label, .stTextInput label, .stNumberInput label, .stSelectbox label { color:#E8E8EA !important; font-weight:600; }
.stMetric { background: #141418; border: 1px solid #2a2a33; border-radius: 10px; padding: 6px 10px; }
.card { border:1px solid #2a2a33; border-radius:10px; padding:12px; background:#111116; }
.callout { border-left:3px solid #E0C36D; padding-left:10px; }
.helper { color:#cfcfd6; font-size:0.9em; margin-top:-8px; margin-bottom:6px; }
.badge { display:inline-block; font-size:0.8em; padding:2px 8px; border-radius:999px; border:1px solid #383842; color:#ddd; }
.badge.good { border-color:#3d6; color:#9f9; }
.badge.mid  { border-color:#cc4; color:#ff8; }
.badge.low  { border-color:#d66; color:#f99; }
.small { font-size:0.9em; color: #bdbdd0; }
hr { border: none; border-top: 1px solid #22222a; margin: 0.6rem 0; }
</style>
""", unsafe_allow_html=True)

# ==========
# DB Layer
# ==========

DB = "timesculpt.db"
logging.basicConfig(level=logging.INFO, format="%(levelname)s:%(message)s")

def _conn():
    c = sqlite3.connect(DB)
    c.row_factory = lambda cur,row: {d[0]: row[i] for i,d in enumerate(cur.description)}
    return c

def run(q, p=(), commit=True):
    try:
        with _conn() as c:
            cur = c.cursor()
            cur.execute(q, p)
            if commit: c.commit()
            return True
    except sqlite3.OperationalError as e:
        logging.error(f"DB error: {e} in query: {q}")
        return False

def fetch(q, p=()):
    try:
        with _conn() as c:
            return c.cursor().execute(q, p).fetchall()
    except sqlite3.OperationalError as e:
        logging.error(f"DB fetch error: {e} in query: {q}")
        return []

def init_db():
    with _conn() as c:
        c.executescript("""
        CREATE TABLE IF NOT EXISTS profiles(
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          name TEXT UNIQUE,
          pin_hash BLOB
        );
        CREATE TABLE IF NOT EXISTS settings(
          profile_id INTEGER, key TEXT, val TEXT,
          PRIMARY KEY(profile_id,key)
        );
        CREATE TABLE IF NOT EXISTS days(
          profile_id INTEGER, d TEXT, note TEXT, state TEXT,
          focus REAL, energy REAL, progress REAL,
          PRIMARY KEY(profile_id, d)
        );
        CREATE TABLE IF NOT EXISTS loops(
          profile_id INTEGER, d TEXT, name TEXT, amount REAL, unit TEXT,
          PRIMARY KEY(profile_id, d, name)
        );
        CREATE TABLE IF NOT EXISTS custom_loops(
          profile_id INTEGER, name TEXT, category TEXT, polarity INTEGER,
          unit TEXT, rate_label TEXT, rate_value REAL,
          PRIMARY KEY(profile_id, name)
        );
        CREATE TABLE IF NOT EXISTS lens(
          profile_id INTEGER, name TEXT, data TEXT,
          PRIMARY KEY(profile_id, name)
        );
        CREATE TABLE IF NOT EXISTS lens_memory(
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          profile_id INTEGER, at TEXT, lens_name TEXT, kind TEXT, phrase TEXT,
          ctx TEXT
        );
        CREATE TABLE IF NOT EXISTS interventions_log(
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          profile_id INTEGER, at TEXT, title TEXT, accepted INTEGER, helped INTEGER
        );
        CREATE TABLE IF NOT EXISTS interventions_log_ctx(
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          profile_id INTEGER, at TEXT, title TEXT, ctx TEXT, reward REAL
        );
        CREATE TABLE IF NOT EXISTS forecast_feedback(
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          profile_id INTEGER, at TEXT, accurate INTEGER
        );
        """)
        c.commit()

init_db()

# ------------
# Profiles
# ------------

def list_profiles(): return fetch("SELECT * FROM profiles ORDER BY name ASC")
def create_profile(name, pin=None):
    pin_hash = None
    if pin and bcrypt:
        pin_hash = bcrypt.hashpw(pin.encode(), bcrypt.gensalt())
    return run("INSERT INTO profiles(name,pin_hash) VALUES(?,?)", (name, pin_hash))

def verify_pin(profile_id, pin) -> bool:
    if not bcrypt or not pin: return True
    row = fetch("SELECT pin_hash FROM profiles WHERE id=?", (profile_id,))
    if not row or row[0]["pin_hash"] is None: return True
    return bcrypt.checkpw(pin.encode(), row[0]["pin_hash"])

def settings_get(pid, k, default=""):
    r = fetch("SELECT val FROM settings WHERE profile_id=? AND key=?", (pid, k))
    return r[0]["val"] if r else default

def settings_set(pid,k,v):
    return run("INSERT OR REPLACE INTO settings(profile_id,key,val) VALUES(?,?,?)", (pid,k,str(v)))

# ------------
# Lens system
# ------------

CORE_LENS = {
    "name": "Core",
    "collapse": [
        "Release what drags the timeline.",
        "Close the tab. End the loop.",
        "No path opens while you hold every door."
    ],
    "recursion": [
        "Repeat the action that proves the future.",
        "Small loops compound into fate.",
        "Consistency sculpts identity."
    ],
    "emergence": [
        "Invite the first true move.",
        "Bend toward the version of you that acts.",
        "Begin poorly. Arrival happens mid-motion."
    ],
    "neutral": [
        "Attend to what is here. Choose again."
    ]
}

def strict_lens_schema(data: dict) -> Optional[dict]:
    """Validate uploaded lens JSON -> normalized dict or None."""
    if not isinstance(data, dict): return None
    out = {"collapse": [], "recursion": [], "emergence": [], "neutral": []}
    for k in out.keys():
        arr = data.get(k, [])
        if arr is None: arr = []
        if not isinstance(arr, list): return None
        clean = []
        for x in arr:
            if isinstance(x, str):
                s = " ".join(x.split())
                if len(s) >= 4:
                    clean.append(s[:400])
        out[k] = clean[:400]
    return out

def lens_put(pid, name, data_dict):
    return run("INSERT OR REPLACE INTO lens(profile_id,name,data) VALUES(?,?,?)",
               (pid, name.strip(), json.dumps(data_dict)))

def lens_all(pid): return fetch("SELECT * FROM lens WHERE profile_id=?", (pid,))

def get_all_lenses_dict(pid):
    out = {"Core": CORE_LENS}
    for r in lens_all(pid):
        try:
            d = json.loads(r["data"])
            valid = strict_lens_schema(d)
            if valid:
                out[r["name"]] = {"name": r["name"], **valid}
        except Exception:
            continue
    return out

def log_lens_memory(pid, lens_name, kind, phrase, ctx):
    run("INSERT INTO lens_memory(profile_id,at,lens_name,kind,phrase,ctx) VALUES(?,?,?,?,?,?)",
        (pid, dt.datetime.now().isoformat(), lens_name, kind, phrase, json.dumps(ctx or {})))

def lens_memory_recent(pid, limit=50):
    return fetch("SELECT * FROM lens_memory WHERE profile_id=? ORDER BY id DESC LIMIT ?", (pid, limit))

def smart_lens_line(pid, kind, ctx, primary_name, secondary_name=None, blend=0.0):
    """Memory + context aware selection from one or blended lenses."""
    all_lenses = get_all_lenses_dict(pid)
    l1 = all_lenses.get(primary_name or "Core", CORE_LENS)
    l2 = all_lenses.get(secondary_name, None) if secondary_name else None

    def pool_for(lens, k):
        return lens.get(k, []) or CORE_LENS.get(k, []) or []

    pool1 = pool_for(l1, kind)
    pool = pool1[:]
    if l2 and blend > 0.0:
        pool2 = pool_for(l2, kind)
        # proportional blend; ensure presence
        w2 = max(1, int(round(3 * float(blend))))
        pool.extend(pool2 * w2)

    if not pool:
        return ""

    # Anti-repetition by recent memory
    recent = lens_memory_recent(pid, limit=12)
    seen = {r["phrase"] for r in recent if r.get("kind") == kind}

    candidates = [p for p in pool if p not in seen] or pool

    # Context boost by goal words
    goal = (ctx.get("goal") or "").lower()
    weighted = []
    for p in candidates:
        sc = 1
        if goal and any(w for w in goal.split() if w and w in p.lower()):
            sc += 2
        weighted.extend([p]*sc)

    phrase = random.choice(weighted) if weighted else random.choice(candidates)
    ln = (secondary_name if (l2 and blend > 0) else l1.get("name", "Core"))
    log_lens_memory(pid, ln, kind, phrase, ctx)
    return phrase

# ------------
# Units & Loops
# ------------

BUILTINS = [
    # name, category, polarity(+1/-1), default unit, rate_label, rate_value
    ("creation:writing",      "creation", +1, "minutes", "pages per minute", 1.0),
    ("creation:project",      "creation", +1, "minutes", "weight (mins=mins)", 1.0),
    ("mind:planning",         "mind",     +1, "minutes", "weight (mins=mins)", 1.0),
    ("mind:reading",          "mind",     +1, "pages",   "pages per minute", 1.0),
    ("mind:meditation",       "mind",     +1, "minutes", "weight (mins=mins)", 1.0),
    ("body:walk",             "body",     +1, "minutes", "weight (mins=mins)", 1.0),
    ("body:exercise",         "body",     +1, "minutes", "reps per minute",  10.0),
    ("body:sleep_good",       "body",     +1, "hours",   "minutes per hour", 60.0),
    ("body:late_sleep",       "body",     -1, "minutes", "weight (mins=mins)", 1.0),
    ("consumption:scroll",    "consumption", -1, "minutes", "weight (mins=mins)", 1.0),
    ("consumption:youtube",   "consumption", -1, "minutes", "weight (mins=mins)", 1.0),
    ("food:junk",             "food",     -1, "servings", "mins per serving", 15.0),
    ("finance:save_invest",   "finance",  +1, "pounds",  "£ per minute",     20.0),
    ("finance:budget_check",  "finance",  +1, "minutes", "weight (mins=mins)", 1.0),
    ("finance:impulse_spend", "finance",  -1, "pounds",  "£ per minute",     20.0),
]

def upsert_builtin_loops(pid):
    have = {r["name"] for r in fetch("SELECT name FROM custom_loops WHERE profile_id=?", (pid,))}
    for name,cat,pol,unit,rl,rv in BUILTINS:
        if name not in have:
            run("""INSERT OR REPLACE INTO custom_loops(profile_id,name,category,polarity,unit,rate_label,rate_value)
                   VALUES(?,?,?,?,?,?,?)""", (pid,name,cat,pol,unit,rl,rv))

def custom_loops_all(pid):
    return fetch("SELECT * FROM custom_loops WHERE profile_id=? ORDER BY category,name", (pid,))

def custom_loop_add(pid, name, category, polarity, unit, rate_label, rate_value):
    if not name.strip(): return False
    return run("""INSERT OR REPLACE INTO custom_loops(profile_id,name,category,polarity,unit,rate_label,rate_value)
                  VALUES(?,?,?,?,?,?,?)""", (pid, name.strip(), category, int(polarity), unit, rate_label, float(rate_value)))

def normalize_amount(row_name: str, amount: float, unit: str, overrides: Dict[str, Dict]) -> float:
    """Return 'effective minutes' for scoring; uses per-loop unit calibration."""
    if amount <= 0: return 0.0
    o = overrides.get(row_name)
    if not o:
        # Fallback: 1 unit == 1 minute if unknown
        return float(amount)
    base_unit = o.get("unit", "minutes")
    rate = float(o.get("rate_value", 1.0))
    # Convert amount to minutes-equivalent by unit type
    if unit == "minutes":
        return float(amount)
    if unit == "hours":
        return float(amount) * 60.0
    if unit == "pages":
        # pages/minute => minutes = pages / (pages per minute)
        ppm = max(0.1, rate)
        return float(amount) / ppm
    if unit == "reps":
        # reps/min => minutes = reps / rpm
        rpm = max(0.1, rate)
        return float(amount) / rpm
    if unit in ("pounds", "£"):
        # £ per minute => minutes = pounds / rate
        pounds_per_min = max(0.1, rate)
        return float(amount) / pounds_per_min
    if unit == "servings":
        # minutes per serving => minutes = servings * rate
        return float(amount) * max(0.0, rate)
    # default fallback
    return float(amount)

# ------------
# Days & Save
# ------------

def save_day(pid, d, note, loops_dict, units_dict, state, F, E, P):
    run("INSERT OR REPLACE INTO days(profile_id,d,note,state,focus,energy,progress) VALUES(?,?,?,?,?,?,?)",
        (pid, d, note, state, F, E, P))
    # store raw loop amount + unit for transparency
    for k, amt in loops_dict.items():
        unit = units_dict.get(k, "minutes")
        run("INSERT OR REPLACE INTO loops(profile_id,d,name,amount,unit) VALUES(?,?,?,?,?)",
            (pid, d, k, float(amt), unit))

def load_days(pid, n=180):
    ds = fetch("SELECT * FROM days WHERE profile_id=? ORDER BY d ASC", (pid,))
    ls = fetch("SELECT * FROM loops WHERE profile_id=?", (pid,))
    by = {}
    for r in ls:
        by.setdefault((r["d"]), {})[r["name"]] = {"amount": r["amount"], "unit": r.get("unit") or "minutes"}
    days = []
    for d in ds:
        key = d["d"]
        d["loops_raw"] = by.get(key, {})
        days.append(d)
    return days[-n:] if n else days

def undo_last_commit(pid):
    rows = fetch("SELECT d FROM days WHERE profile_id=? ORDER BY d DESC LIMIT 1", (pid,))
    if not rows: return False
    d = rows[0]["d"]
    run("DELETE FROM days WHERE profile_id=? AND d=?", (pid, d))
    run("DELETE FROM loops WHERE profile_id=? AND d=?", (pid, d))
    return True

# ------------
# State Model
# ------------

W_POS, W_NEG, W_PROG, W_ENER = 0.8, 0.9, 0.25, 0.15
STATES = ["Focused", "Mixed", "Drift"]
IDX = {s:i for i,s in enumerate(STATES)}

def label_state(loops_eff: Dict[str, float], pos_keys: set, neg_keys: set):
    posm = sum(loops_eff.get(k, 0.0) for k in pos_keys)
    negm = sum(loops_eff.get(k, 0.0) for k in neg_keys)

    energy = min(100.0, (
        loops_eff.get("body:walk", 0.0)*1.2 +
        loops_eff.get("body:exercise", 0.0)*1.6 +
        loops_eff.get("body:sleep_good", 0.0)*0.8
    ) / 2.0)

    progress = min(100.0, (
        loops_eff.get("creation:writing", 0.0)*1.4 +
        loops_eff.get("creation:project", 0.0)*1.2 +
        loops_eff.get("finance:save_invest", 0.0)*1.1 +
        loops_eff.get("mind:planning", 0.0)*0.9
    ))

    focus_raw = (posm * W_POS - negm * W_NEG) + progress * W_PROG + energy * W_ENER
    focus = max(0.0, min(100.0, focus_raw))

    if negm > posm * 1.2 or loops_eff.get("consumption:scroll", 0.0) >= 45:
        state = "Drift"
    elif posm >= negm and (loops_eff.get("creation:writing", 0.0) + loops_eff.get("creation:project", 0.0)) >= 30:
        state = "Focused"
    else:
        state = "Mixed"

    contribs = []
    for k in pos_keys:
        m = loops_eff.get(k, 0.0)
        if m > 0: contribs.append((k, m*W_POS, m))
    for k in neg_keys:
        m = loops_eff.get(k, 0.0)
        if m > 0: contribs.append((k, -m*W_NEG, m))

    pos_sorted = sorted([c for c in contribs if c[1] > 0], key=lambda x: -x[1])[:2]
    neg_sorted = sorted([c for c in contribs if c[1] < 0], key=lambda x: abs(x[1]), reverse=True)[:2]

    def fmt_pos(c): return f"+{int(c[2])}m {c[0].split(':',1)[1]} (impact +{c[1]:.1f})"
    def fmt_neg(c): return f"-{int(c[2])}m {c[0].split(':',1)[1]} (impact {c[1]:.1f})"
    plus  = ", ".join(fmt_pos(c) for c in pos_sorted) if pos_sorted else "+0m"
    minus = ", ".join(fmt_neg(c) for c in neg_sorted) if neg_sorted else "-0m"
    micro = f"{plus} | {minus}"

    return state, round(focus,1), round(energy,1), round(progress,1), micro

# ------------
# Forecast (Dirichlet calibration + adaptive sims)
# ------------

DECAY = 0.97
PRIOR_WEIGHT = 0.5
UNIFORM_BLEND = 0.08

def learn_matrix(days, decay=DECAY):
    C = np.ones((3,3)) * PRIOR_WEIGHT
    last = None; w = 1.0
    for d in days:
        s = d.get("state")
        if s not in IDX: continue
        if last is not None:
            C[IDX[last], IDX[s]] += w
        w *= decay
        last = s
    M = C / C.sum(axis=1, keepdims=True)
    U = np.ones((3,3))/3.0
    M = (1-UNIFORM_BLEND)*M + UNIFORM_BLEND*U
    M = np.maximum(1e-6, M)
    return M / M.sum(axis=1, keepdims=True)

def entropy_of_matrix(M):
    # average row entropy (0..~1.1)
    ent = 0.0
    for i in range(M.shape[0]):
        p = M[i] + 1e-9
        ent += -np.sum(p*np.log(p))
    return ent / M.shape[0]

def adaptive_sims(M):
    ent = entropy_of_matrix(M)
    # low entropy → fewer sims; higher entropy → more sims
    return int(np.clip(800 + 2000*(ent/1.1), 800, 3000))

def simulate(M, start_state, days=30, sims=1500):
    start = IDX.get(start_state, 1)
    counts = np.zeros((days, 3))
    for _ in range(sims):
        s = start
        for t in range(days):
            counts[t, s] += 1
            s = np.random.choice([0,1,2], p=M[s])
    probs = counts / sims
    exp_focus = probs[:,0].sum()
    return probs, float(exp_focus)

def calibrate_matrix(M, pid):
    """Dirichlet posterior from real transitions + feedback nudges."""
    days = load_days(pid, 120)
    alpha = np.ones((3,3)) * PRIOR_WEIGHT
    last = None; w = 1.0
    for d in days:
        s = d.get("state")
        if s not in IDX: continue
        if last is not None:
            alpha[IDX[last], IDX[s]] += w
        w *= DECAY
        last = s

    fb = fetch("SELECT accurate FROM forecast_feedback WHERE profile_id=?", (pid,))
    good = sum(1 for r in fb if int(r["accurate"] or 0) == 1)
    bad  = sum(1 for r in fb if int(r["accurate"] or 0) == 0)

    boost = 1.0 + 0.01*good
    damp  = 1.0 + 0.01*bad

    for i in range(3):
        alpha[i,i] *= boost
        for j in range(3):
            if j!=i: alpha[i,j] /= damp

    M2 = alpha / alpha.sum(axis=1, keepdims=True)
    U = np.ones((3,3))/3.0
    M2 = (1-UNIFORM_BLEND)*M2 + UNIFORM_BLEND*U

    # Confidence badge from KL-divergence between prior M and calibrated M2
    eps = 1e-9
    kl = 0.0
    for i in range(3):
        p = M[i]  + eps
        q = M2[i] + eps
        kl += np.sum(p * np.log(p/q))
    kl /= 3.0
    if kl > 0.05: conf = "High"
    elif kl > 0.02: conf = "Medium"
    else: conf = "Low"
    return (M2 / M2.sum(axis=1, keepdims=True)), conf

# ------------
# Interventions (pool + contextual bandit)
# ------------

def interventions_pool(goal_text: str):
    gl = (goal_text or "").lower()
    finance_goal = any(w in gl for w in ["save","invest","debt","money","budget"])
    writing_goal = any(w in gl for w in ["write","book","essay","draft"])
    fitness_goal = any(w in gl for w in ["walk","run","gym","weight"])

    pool = [
        {"title":"7-min starter", "how":"Start badly. Stop after 7.", "tags":["creation"], "tweak":{"m_to_f":+0.05}},
        {"title":"15-min walk", "how":"Swap one scroll for a short walk.", "tags":["body"], "tweak":{"m_to_f":+0.05, "d_self":-0.03}},
        {"title":"Sleep before midnight", "how":"Shutdown 30 min earlier.", "tags":["body"], "tweak":{"d_self":-0.06}},
        {"title":"10% pay-yourself-first", "how":"Automate a standing order.", "tags":["finance"], "tweak":{"m_to_f":+0.05}},
    ]
    # Bias pool by goal
    if finance_goal:
        pool.append({"title":"Budget check (5m)","how":"Scan top 3 expenses.","tags":["finance"],"tweak":{"m_to_f":+0.03}})
    if writing_goal:
        pool.append({"title":"1 paragraph now","how":"Just 3 sentences.","tags":["creation"],"tweak":{"m_to_f":+0.04}})
    if fitness_goal:
        pool.append({"title":"Pushups x20","how":"Do them next.","tags":["body"],"tweak":{"m_to_f":+0.03, "d_self":-0.02}})
    return pool

def tweak_matrix(M, **kwargs):
    A = M.copy()
    def adj_row(i, d):
        A[i] = np.maximum(0.001, A[i] + d)
        A[i] /= A[i].sum()
    if kwargs.get("d_self"): adj_row(IDX["Drift"], np.array([0,0,kwargs["d_self"]]))
    if kwargs.get("d_to_m"):  adj_row(IDX["Drift"], np.array([0,kwargs["d_to_m"],0]))
    if kwargs.get("m_to_f"):  adj_row(IDX["Mixed"], np.array([kwargs["m_to_f"],0,0]))
    if kwargs.get("f_self"):  adj_row(IDX["Focused"], np.array([kwargs["f_self"],0,0]))
    return A

def log_intervention(pid, title, accepted=False, helped=None):
    run("INSERT INTO interventions_log(profile_id,at,title,accepted,helped) VALUES(?,?,?,?,?)",
        (pid, dt.datetime.now().isoformat(), title, int(bool(accepted)),
         (None if helped is None else int(bool(helped)))))

def log_intervention_ctx(pid, title, ctx_vec, helped=None):
    run("INSERT INTO interventions_log_ctx(profile_id,at,title,ctx,reward) VALUES(?,?,?,?,?)",
        (pid, dt.datetime.now().isoformat(), title, json.dumps(list(map(float,ctx_vec))),
         (None if helped is None else (1.0 if helped else 0.0))))

def last7_avg(days, key):
    vals=[]
    for d in days[-7:]:
        loops = d.get("loops_eff") or {}
        vals.append(float(loops.get(key,0.0)))
    return float(np.mean(vals)) if vals else 0.0

def goal_kind_flags(goal_text:str):
    g=(goal_text or "").lower()
    return [
        1.0 if any(w in g for w in ["write","book","essay","draft"]) else 0.0,
        1.0 if any(w in g for w in ["fit","weight","walk","run","gym"]) else 0.0,
        1.0 if any(w in g for w in ["save","invest","debt","money"]) else 0.0,
        1.0 if any(w in g for w in ["learn","study","course","read"]) else 0.0,
    ]

def current_context_vec(days, goal_text, start_state):
    onehot = [0.0,0.0,0.0]; onehot[IDX.get(start_state,1)] = 1.0
    sleep_g  = last7_avg(days,"body:sleep_good")
    late_slp = last7_avg(days,"body:late_sleep")
    scroll   = last7_avg(days,"consumption:scroll")
    exercise = last7_avg(days,"body:exercise")
    writing  = last7_avg(days,"creation:writing")
    gflags   = goal_kind_flags(goal_text)
    return [
        1.0, *onehot,
        sleep_g/60.0, late_slp/60.0, scroll/60.0, exercise/60.0, writing/60.0,
        np.mean([d.get("focus",50.0) for d in days[-7:]])/100.0,
        *gflags
    ]

def _linreg_posterior(X, y, alpha=1.0, sigma2=0.35):
    d = X.shape[1]
    A = alpha*np.eye(d) + X.T @ X
    b = X.T @ y
    try: Ainv = np.linalg.inv(A)
    except np.linalg.LinAlgError: Ainv = np.linalg.pinv(A)
    mu = Ainv @ b
    cov = sigma2 * Ainv
    return mu, cov

def _get_arm_data(pid, title):
    rows = fetch("SELECT ctx, reward FROM interventions_log_ctx WHERE profile_id=? AND title=? AND reward IS NOT NULL",
                 (pid, title))
    X=[]; y=[]
    for r in rows:
        try:
            v = json.loads(r["ctx"]); rr = float(r["reward"])
            if isinstance(v, list):
                X.append(v); y.append(rr)
        except Exception:
            continue
    if not X: return None, None
    return np.array(X, dtype=float), np.array(y, dtype=float)

def bandit_context_scores(pid, context_vec, titles):
    x = np.array(context_vec, dtype=float).reshape(1,-1)
    scores={}
    for t in titles:
        X,y = _get_arm_data(pid, t)
        if X is None:
            scores[t] = 0.55 + np.random.normal(0, 0.05)  # optimistic prior
            continue
        mu, cov = _linreg_posterior(X,y)
        try:
            theta = np.random.multivariate_normal(mu, cov)
        except Exception:
            theta = mu
        scores[t] = float(x @ theta)[0]
    return scores

# ------------
# AI helpers
# ------------

def ai_available(): return _openai_client is not None

def safe_ai_call(prompt: str, system: str = "You are a concise coach."):
    if not ai_available(): return None
    try:
        resp = _openai_client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.5,
            messages=[{"role":"system","content":system},{"role":"user","content":prompt}]
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception:
        return None

def ai_narrate_forecast_rich(goal, start_state, focused_days, likelihood_mid, likelihood_band,
                             required_pace_delta, milestones, top_move, top_move_delta,
                             alt_upside, drivers_pos, drivers_neg):
    sys = "You turn behavioral forecasts into one crisp paragraph. Be concrete and motivational without fluff."
    lo, hi = likelihood_band
    parts = [
        f"Goal: {goal or '—'}.",
        f"Expected focused days: {focused_days:.1f}/30.",
        f"Chance to hit plan: {likelihood_mid:.0%} (range {lo:.0%}–{hi:.0%}).",
    ]
    if required_pace_delta > 0.05:
        parts.append(f"To keep pace, add ~{required_pace_delta:.1f} units daily.")
    if milestones:
        parts.append(f"Near-term milestones: {', '.join(milestones[:2])}.")
    if drivers_pos: parts.append(f"Tailwinds: {', '.join(drivers_pos[:2])}.")
    if drivers_neg: parts.append(f"Headwinds: {', '.join(drivers_neg[:2])}.")
    parts.append(f"Smallest move now: {top_move} (≈ +{top_move_delta:.2f} days).")

    prompt = " ".join(parts) + " Rewrite into one tight paragraph in plain language."
    out = safe_ai_call(prompt, sys)
    return out

def local_narrate_forecast(goal: str, start_state: str, focused_days: float,
                           likelihood_mid: float, likelihood_band: tuple,
                           required_pace_delta: float, unit_label: str,
                           milestones: list, drivers_pos: list, drivers_neg: list,
                           top_move_title: str, top_move_delta: float) -> str:
    lo, hi = likelihood_band
    parts = []
    if goal: parts.append(f"Goal: **{goal}**.")
    parts.append(f"Next 30 days: **{focused_days:.1f}** focused days expected.")
    parts.append(f"Chance of hitting plan: **{likelihood_mid:.0%}** (range {lo:.0%}–{hi:.0%}).")
    if required_pace_delta > 0.1:
        parts.append(f"To stay on track: add ~**{required_pace_delta:.1f} {unit_label}** daily.")
    if milestones:  parts.append(f"Near-term milestones: _{', '.join(milestones[:2])}_.")
    if drivers_pos: parts.append(f"Tailwinds: {', '.join(drivers_pos[:2])}.")
    if drivers_neg: parts.append(f"Headwinds: {', '.join(drivers_neg[:2])}.")
    if top_move_title:
        parts.append(f"Smallest move now: **{top_move_title}** (≈ +{top_move_delta:.2f} days).")
    return " ".join(parts)

# =========================
# Sidebar: Profiles & Nav
# =========================

with st.sidebar:
    st.title("TimeSculpt")
    # AI toggle
    USE_AI = st.toggle("AI narration", value=False, help="Turn on to get AI-written briefs. Off = local narration.")
    st.divider()

    # Profiles
    profs = list_profiles()
    prof_names = ["(create new)"] + [p["name"] for p in profs]
    sel = st.selectbox("Profile", prof_names, index=(1 if profs else 0))
    if sel == "(create new)":
        with st.expander("Create profile"):
            n = st.text_input("Name")
            p = st.text_input("Optional PIN", type="password")
            if st.button("Create"):
                if create_profile(n, p): st.success("Profile created. Select it above."); st.experimental_rerun()
                else: st.error("Failed to create profile (name may exist).")
        pid = None
    else:
        pid = [p for p in profs if p["name"] == sel][0]["id"]
        # Optional PIN gate
        row = fetch("SELECT pin_hash FROM profiles WHERE id=?", (pid,))
        need_pin = row and row[0]["pin_hash"] is not None
        if need_pin:
            pin_try = st.text_input("PIN", type="password")
            if st.button("Unlock") and not verify_pin(pid, pin_try):
                st.error("Wrong PIN.")
                pid = None

    st.divider()
    tabs = ["Input","Forecast","Interventions","Diagnostics","Lens","Lens Memory","Export/Import","Help"]
    tab = st.radio("Navigate", tabs, index=0)

# Protect UI if no profile
if not pid:
    st.info("Create or unlock a profile to begin.")
    st.stop()

# Ensure builtins in custom_loops
upsert_builtin_loops(pid)

# Sticky header
days_all = load_days(pid, 365)
st.markdown("<div style='position:sticky;top:0;background:#0d0d10e6;border-bottom:1px solid #222;padding:.35rem 0;z-index:50'>", unsafe_allow_html=True)
hdr = f"<span class='badge'>Profile: {sel}</span> "
if days_all:
    last = days_all[-1]
    hdr += f"&nbsp;&nbsp;<b>Today:</b> {last['state']} • Focus {last['focus']:.0f} • Energy {last['energy']:.0f} • Progress {last['progress']:.0f}"
else:
    hdr += "&nbsp;&nbsp;<b>Today:</b> no data yet"
st.markdown(hdr, unsafe_allow_html=True)
st.markdown("</div>", unsafe_allow_html=True)

# =============
# INPUT TAB
# =============
if tab == "Input":
    st.header("Daily Input")
    goal = st.text_input("Objective / Goal", value=settings_get(pid,"goal",""))
    if st.button("Save goal"): settings_set(pid,"goal",goal); st.success("Goal saved.")
    st.caption("Tip: your interventions and narration are biased toward this objective.")

    # Custom loops table + builder
    st.subheader("Your Loops")
    loops_meta = custom_loops_all(pid)
    meta_map = {r["name"]: r for r in loops_meta}

    with st.expander("Add or calibrate a loop"):
        c1,c2,c3 = st.columns(3)
        with c1: new_name = st.text_input("Name (e.g., reading)")
        with c2: new_cat  = st.selectbox("Category", ["creation","mind","body","consumption","food","finance"])
        with c3: new_pol  = st.selectbox("Polarity", [+1,-1], format_func=lambda x: "Positive (+)" if x>0 else "Negative (−)")
        c4,c5,c6 = st.columns(3)
        with c4: new_unit = st.selectbox("Unit", ["minutes","hours","pages","reps","servings","pounds","£"])
        with c5: rate_label = st.text_input("Rate label", value=("pages per minute" if new_unit=="pages" else "weight (mins=mins)"))
        with c6: rate_value = st.number_input("Rate value", min_value=0.01, max_value=9999.0, value=1.0, step=0.1)

        if st.button("Add/Update loop"):
            ok = custom_loop_add(pid, f"{new_cat}:{new_name}", new_cat, new_pol, new_unit, rate_label, rate_value)
            if ok: st.success("Loop saved."); st.experimental_rerun()
            else:  st.error("Loop save failed.")

    # Inputs for today
    d = st.date_input("Date", value=dt.date.today()).isoformat()
    st.caption("Enter values; the system normalizes units to effective minutes for scoring.")

    # Prepare fields in a grid
    names_sorted = sorted(meta_map.keys())
    cols = st.columns(4)
    loops_amount, loops_unit = {}, {}
    for i, name in enumerate(names_sorted):
        row = meta_map[name]
        label = f"{name.split(':',1)[1].title()}"
        with cols[i%4]:
            amt = st.number_input(label, min_value=0.0, max_value=9999.0, value=0.0, step=1.0, key=f"amt_{name}")
            unit = st.selectbox("unit", ["minutes","hours","pages","reps","servings","pounds","£"], index=["minutes","hours","pages","reps","servings","pounds","£"].index(row["unit"]) if row["unit"] in ["minutes","hours","pages","reps","servings","pounds","£"] else 0, key=f"unit_{name}")
            st.markdown(f"<div class='helper'>Calib: {row['rate_label']} = <b>{row['rate_value']}</b></div>", unsafe_allow_html=True)
            loops_amount[name] = amt
            loops_unit[name]   = unit

    # Normalize to effective minutes and label state
    # Build pos/neg sets
    pos_keys = {r["name"] for r in loops_meta if int(r["polarity"]) > 0}
    neg_keys = {r["name"] for r in loops_meta if int(r["polarity"]) < 0}
    overrides = {r["name"]: r for r in loops_meta}

    loops_eff = {}
    for k, amt in loops_amount.items():
        loops_eff[k] = normalize_amount(k, amt, loops_unit.get(k,"minutes"), overrides)

    state, F, E, P, micro = label_state(loops_eff, pos_keys, neg_keys)
    st.info(f"**{state}** • Focus {F} • Energy {E} • Progress {P}\n\n{micro}")

    note = st.text_area("Note (optional)")
    c1,c2 = st.columns(2)
    with c1:
        if st.button("Commit today"):
            # Attach normalized loops to days (also store raw w/ unit)
            day_record = {"loops_eff": loops_eff}
            save_day(pid, d, note, loops_amount, loops_unit, state, F, E, P)
            st.success("Saved.")
    with c2:
        if st.button("Undo last commit"):
            if undo_last_commit(pid): st.success("Undone."); st.experimental_rerun()
            else: st.info("Nothing to undo.")

# =============
# FORECAST TAB
# =============
elif tab == "Forecast":
    st.header("30-Day Forecast")

    days = load_days(pid, 180)
    if not days:
        st.info("Log at least 1 day to unlock forecast.")
        st.stop()

    # attach loops_eff for context features (compute from raw using overrides)
    overrides = {r["name"]: r for r in custom_loops_all(pid)}
    for drow in days:
        eff = {}
        for name, raw in (drow.get("loops_raw") or {}).items():
            amt, unit = raw.get("amount",0.0), raw.get("unit","minutes")
            eff[name] = normalize_amount(name, amt, unit, overrides)
        drow["loops_eff"] = eff

    start = days[-1]["state"]
    goal_text = settings_get(pid,"goal","")
    M = learn_matrix(days)
    M_calib, conf = calibrate_matrix(M, pid)
    sims = adaptive_sims(M_calib)
    probs, expF = simulate(M_calib, start, 30, sims)

    df = pd.DataFrame({"day": range(1,31), "Focused": probs[:,0], "Mixed": probs[:,1], "Drift": probs[:,2]})
    dfm = df.melt("day", var_name="state", value_name="p")

    # Stats row: sparkline + metrics
    last14 = days[-14:] if len(days) >= 1 else []
    s_focus = [d.get("focus",0) for d in last14]
    df_spark = pd.DataFrame({"idx": list(range(len(s_focus))), "focus": s_focus}) if s_focus else pd.DataFrame({"idx":[0], "focus":[0]})

    c1,c2,c3,c4 = st.columns([2,1,1,1])
    with c1:
        st.caption("Last 14 days — Focus trend")
        st.altair_chart(alt.Chart(df_spark).mark_line().encode(x="idx", y="focus").properties(height=60), use_container_width=True)
    with c2:
        st.metric("Expected focused days (30d)", f"{df['Focused'].sum():.1f}")
    with c3:
        st.metric("Current state", start)
    with c4:
        badge = f"<span class='badge {'good' if conf=='High' else 'mid' if conf=='Medium' else 'low'}'>Confidence: {conf}</span>"
        st.markdown(badge, unsafe_allow_html=True)

    # Area chart
    st.altair_chart(
        alt.Chart(dfm).mark_area(opacity=0.9).encode(
            x="day:Q",
            y=alt.Y("p:Q", stack="normalize", axis=alt.Axis(format="%")),
            color=alt.Color("state:N", scale=alt.Scale(domain=["Focused","Mixed","Drift"], range=["#E0C36D","#888","#B91C1C"]))
        ).properties(height=260),
        use_container_width=True
    )

    # Scenario compare (canned)
    with st.expander("Compare scenarios"):
        baseF = float(df["Focused"].sum())
        goal = settings_get(pid,"goal","")
        POOL = interventions_pool(goal)
        start_state = start

        # context-aware top move
        ctx_vec = current_context_vec(days, goal, start_state)
        titles = [iv["title"] for iv in POOL]
        scores = bandit_context_scores(pid, ctx_vec, titles)

        def sim_delta(iv):
            M2 = tweak_matrix(M_calib, **iv["tweak"])
            probs2, _ = simulate(M2, start_state, 30, adaptive_sims(M2))
            return float(probs2[:,0].sum() - baseF)

        candidates = []
        for iv in POOL:
            delta = sim_delta(iv)
            bscore = scores.get(iv["title"], 0.5)
            blended = 0.7*delta + 0.3*(bscore-0.5)  # mild bandit bias
            candidates.append({"iv":iv,"delta":delta,"bscore":bscore,"score":blended})
        candidates.sort(key=lambda x: -x["score"])
        best = candidates[0] if candidates else None

        c1,c2 = st.columns(2)
        with c1:
            if best:
                st.markdown("**Scenario A — Top move**")
                st.markdown(f"**{best['iv']['title']}** → Δ Focused days ≈ **+{best['delta']:.2f}**")
                st.caption(best['iv']['how'])
        with c2:
            # demonstrate another option
            alt_iv = candidates[1] if len(candidates)>1 else None
            st.markdown("**Scenario B — Next best**")
            if alt_iv:
                st.markdown(f"**{alt_iv['iv']['title']}** → Δ Focused days ≈ **+{alt_iv['delta']:.2f}**")
                st.caption(alt_iv['iv']['how'])
            else:
                st.write("—")

    # Forecast plausibility feedback
    st.markdown("—")
    st.markdown("**Did this forecast feel right?**")
    c1,c2,c3 = st.columns(3)
    with c1:
        if st.button("Yes, plausible"):
            run("INSERT INTO forecast_feedback(profile_id,at,accurate) VALUES(?,?,1)",
                (pid, dt.datetime.now().isoformat()))
            st.toast("Thanks — model calibrated slightly sharper.", icon="✅")
    with c2:
        if st.button("No, off today"):
            run("INSERT INTO forecast_feedback(profile_id,at,accurate) VALUES(?,?,0)",
                (pid, dt.datetime.now().isoformat()))
            st.toast("Got it — model flattened a notch.", icon="⚠️")
    with c3:
        st.caption("Optional. Skipping is fine.")

    # Rich brief (AI if on, else local) with dual-lens line
    goal_text = settings_get(pid,"goal","")
    # Simple goal likelihood proxy: assume plan target = 20 focused days
    target = 20.0
    lik_mid = np.clip((expF/target), 0.0, 1.25)
    lik_lo, lik_hi = max(0.0, lik_mid - 0.15), min(1.0, lik_mid + 0.15)
    avg_per_day = (sum([sum((d.get("loops_eff") or {}).values()) for d in days[-14:]]) / (14.0 if len(days)>=14 else max(1,len(days))))
    # near-term milestones (illustrative)
    milestones = ["3 focused days this week", "One zero-scroll day"]
    unit_label = "mins"
    # drivers (top pos/neg contributors)
    drivers_pos = []
    drivers_neg = []
    if days_all:
        last = days_all[-1]
        micro = label_state(last.get("loops_eff") or {}, set(), set())[4] if last.get("loops_eff") else ""
        # very light parse
        drivers_pos = [seg.strip() for seg in micro.split("|")[0:1] if seg]
        drivers_neg = [seg.strip() for seg in micro.split("|")[1:2] if seg]

    # Dual lens context
    active_primary = settings_get(pid,"lens_primary","Core") or "Core"
    use_secondary = settings_get(pid,"lens_use_secondary","0") == "1"
    active_secondary = settings_get(pid,"lens_secondary","Core") if use_secondary else None
    blend = float(settings_get(pid,"lens_blend","0.0")) if active_secondary else 0.0

    # Compose brief
    ctx = {"goal": goal_text, "state": start}
    lens_line = smart_lens_line(pid, "emergence", ctx, active_primary, active_secondary, blend)

    # Build top-move again for brief (reuse best)
    top_title = (best["iv"]["title"] if best else "")
    top_delta = (best["delta"] if best else 0.0)

    st.markdown("### Forecast brief")
    brief_text = ""
    if USE_AI and ai_available():
        try:
            brief_text = ai_narrate_forecast_rich(
                goal=goal_text, start_state=start, focused_days=float(df['Focused'].sum()),
                likelihood_mid=lik_mid, likelihood_band=(lik_lo, lik_hi),
                required_pace_delta=max(0.0, (target - expF) / 30.0),
                milestones=milestones,
                top_move=top_title, top_move_delta=top_delta,
                alt_upside="−30m scroll / +15m walk",
                drivers_pos=drivers_pos, drivers_neg=drivers_neg
            )
        except Exception:
            brief_text = ""

    if not brief_text:
        brief_text = local_narrate_forecast(
            goal=goal_text, start_state=start, focused_days=float(df['Focused'].sum()),
            likelihood_mid=lik_mid, likelihood_band=(lik_lo, lik_hi),
            required_pace_delta=max(0.0, (target - expF) / 30.0), unit_label=unit_label,
            milestones=milestones, drivers_pos=drivers_pos, drivers_neg=drivers_neg,
            top_move_title=top_title, top_move_delta=top_delta
        )

    st.markdown(f"<div class='card'>{brief_text}<br><span class='small'>Lens: {lens_line}</span></div>", unsafe_allow_html=True)
    st.caption(f"_Target pace: {target:.0f} {unit_label}; your 14-day avg: {avg_per_day:.1f} {unit_label}_")

# =============
# INTERVENTIONS TAB
# =============
elif tab == "Interventions":
    st.header("Interventions")

    days = load_days(pid, 120)
    if not days:
        st.info("Log at least 1 day.")
        st.stop()

    goal = settings_get(pid, "goal", "")
    M = learn_matrix(days)
    M_calib, _ = calibrate_matrix(M, pid)
    start = days[-1]["state"]
    base_probs, _ = simulate(M_calib, start, 30, adaptive_sims(M_calib))
    baseF = float(base_probs[:,0].sum())

    POOL = interventions_pool(goal)
    ctx_vec = current_context_vec(days, goal, start)
    titles = [iv["title"] for iv in POOL]
    scores = bandit_context_scores(pid, ctx_vec, titles)

    results = []
    for iv in POOL:
        M2 = tweak_matrix(M_calib, **iv["tweak"])
        probs2, _ = simulate(M2, start, 30, adaptive_sims(M2))
        delta = float(probs2[:,0].sum() - baseF)
        bscore = scores.get(iv["title"], 0.5)
        blended = 0.7*delta + 0.3*(bscore-0.5)
        results.append({"iv":iv, "delta":delta, "bscore":bscore, "score":blended})
    results.sort(key=lambda r: -r["score"])
    top = results[0] if results else None

    # Why chip from last state
    micro = ""
    if days_all:
        last = days_all[-1]
        if last.get("state"):
            m_state, _, _, _, m_micro = label_state(last.get("loops_eff") or {}, set(), set())
            micro = m_micro

    if top:
        st.markdown("### ⭐ Top move")
        st.markdown("<div class='card'>", unsafe_allow_html=True)
        st.markdown(f"**{top['iv']['title']}** — {top['iv']['how']}")
        st.markdown(f"Δ Focused days ≈ **+{top['delta']:.2f}** &nbsp;•&nbsp; Bandit score: {top['bscore']:.2f}")
        if micro:
            st.caption(f"Why today: {micro}")
        c1,c2,c3 = st.columns(3)
        with c1:
            if st.button(f"Apply: {top['iv']['title']}"):
                log_intervention(pid, top['iv']['title'], accepted=True)
                log_intervention_ctx(pid, top['iv']['title'], ctx_vec, helped=None)
                st.success("Applied. Tell me later if it helped.")
        with c2:
            fb = st.selectbox("Did it help?", ["Skip","Yes","No"], key="fb_top")
            if st.button("Save feedback"):
                if fb!="Skip":
                    helped = (fb=="Yes")
                    log_intervention(pid, top['iv']['title'], accepted=True, helped=helped)
                    log_intervention_ctx(pid, top['iv']['title'], ctx_vec, helped=helped)
                    st.toast("Learned from your feedback.", icon="🧠")
        with c3:
            st.caption("Bandit update happens instantly on feedback.")
        st.markdown("</div>", unsafe_allow_html=True)

    with st.expander("More options"):
        for r in results[1:]:
            st.markdown(f"**{r['iv']['title']}** — {r['iv']['how']}  \nΔ Focused days ≈ **+{r['delta']:.2f}** (bandit {r['bscore']:.2f})")
            ca, cb, cc = st.columns([1,1,2])
            with ca:
                if st.button(f"Apply: {r['iv']['title']}", key=f"app_{r['iv']['title']}"):
                    log_intervention(pid, r['iv']['title'], accepted=True)
                    log_intervention_ctx(pid, r['iv']['title'], ctx_vec, helped=None)
                    st.success("Applied.")
            with cb:
                fb = st.selectbox("Helped?", ["Skip","Yes","No"], key=f"fb_{r['iv']['title']}")
                if st.button("Save", key=f"s_{r['iv']['title']}"):
                    if fb!="Skip":
                        helped = (fb=="Yes")
                        log_intervention(pid, r['iv']['title'], accepted=True, helped=helped)
                        log_intervention_ctx(pid, r['iv']['title'], ctx_vec, helped=helped)
                        st.toast("Bandit updated.", icon="🧠")
            with cc:
                st.caption(" ")

    st.markdown("---")
    st.subheader("Proven for you")
    dfp = pd.DataFrame(fetch("""
      SELECT title,
             ROUND(AVG(CASE WHEN helped IS NOT NULL THEN helped END)*100.0,1) AS success_pct,
             SUM(CASE WHEN accepted=1 THEN 1 ELSE 0 END) AS trials
      FROM interventions_log
      WHERE profile_id=?
      GROUP BY title
      ORDER BY success_pct DESC NULLS LAST, trials DESC
    """, (pid,)))
    if dfp.empty:
        st.caption("No data yet. Apply and rate a few moves to see your leaderboard.")
    else:
        st.dataframe(dfp, use_container_width=True)

    st.markdown("---")
    st.subheader("Add your own intervention")
    with st.form("add_iv"):
        t = st.text_input("Title")
        h = st.text_area("How to do it")
        st.caption("Tweak (advanced): shift probabilities — small numbers are best.")
        m_to_f = st.number_input("Mixed → Focused (e.g., +0.04)", value=0.0, step=0.01, format="%.2f")
        d_self = st.number_input("Drift self (e.g., −0.03)", value=0.0, step=0.01, format="%.2f")
        submitted = st.form_submit_button("Add")
        if submitted and t.strip():
            existing = interventions_pool(goal)  # not persisted; but we can show how to add at runtime
            # For simplicity we store in session for now
            st.session_state.setdefault("user_iv", [])
            st.session_state["user_iv"].append({"title":t.strip(),"how":h.strip(),"tags":[],"tweak":{"m_to_f":m_to_f,"d_self":d_self}})
            st.success("Added for this session (persistance of custom IVs can be added later).")

# =============
# DIAGNOSTICS TAB
# =============
elif tab == "Diagnostics":
    st.header("Diagnostics")
    st.caption("Force (+) = loops correlated with Focused days. Drift (−) = loops correlated with Drift days. Recency-weighted averages.")

    days = load_days(pid, 180)
    if not days:
        st.info("No data yet.")
        st.stop()

    overrides = {r["name"]: r for r in custom_loops_all(pid)}
    rows=[]
    for d in days:
        eff={}
        for name, raw in (d.get("loops_raw") or {}).items():
            eff[name] = normalize_amount(name, raw.get("amount",0.0), raw.get("unit","minutes"), overrides)
        d["loops_eff"] = eff
        for k,v in eff.items():
            rows.append({"d": d["d"], "k": k, "minutes": v, "state": d["state"]})

    if not rows:
        st.info("No loops logged.")
        st.stop()

    df = pd.DataFrame(rows)
    pivot = df.pivot_table(index="k", columns="state", values="minutes", aggfunc="mean").fillna(0.0)
    # Pad missing columns
    for s in ["Focused","Mixed","Drift"]:
        if s not in pivot.columns:
            pivot[s] = 0.0
    pivot["lift"] = pivot["Focused"] - pivot["Drift"]

    # 14→14 trend
    dts = sorted({r["d"] for r in rows})
    cut = len(dts)//2
    first = set(dts[:cut]); last = set(dts[cut:])
    df1 = df[df["d"].isin(first)]
    df2 = df[df["d"].isin(last)]
    p1 = df1.pivot_table(index="k", columns="state", values="minutes", aggfunc="mean").fillna(0.0)
    p2 = df2.pivot_table(index="k", columns="state", values="minutes", aggfunc="mean").fillna(0.0)
    for s in ["Focused","Mixed","Drift"]:
        for p in (p1,p2):
            if s not in p.columns: p[s]=0.0
    p1["lift"]=p1["Focused"]-p1["Drift"]; p2["lift"]=p2["Focused"]-p2["Drift"]
    trend = (p2["lift"] - p1["lift"]).fillna(0.0)

    best = pivot.sort_values("lift", ascending=False).head(5).copy()
    worst= pivot.sort_values("lift", ascending=True).head(5).copy()
    best["Δ(14→14)"]  = trend.reindex(best.index).fillna(0.0)
    worst["Δ(14→14)"] = trend.reindex(worst.index).fillna(0.0)

    c1,c2 = st.columns(2)
    with c1:
        st.subheader("Force (+)")
        st.dataframe(best[["lift","Focused","Drift","Δ(14→14)"]])
    with c2:
        st.subheader("Drift (−)")
        st.dataframe(worst[["lift","Focused","Drift","Δ(14→14)"]])

# =============
# LENS TAB
# =============
elif tab == "Lens":
    st.header("Lenses")
    st.caption("Upload text to create a lens. Valid keys: collapse, recursion, emergence, neutral → arrays of short lines.")

    # Add / upload
    up = st.file_uploader("Upload .txt / .docx / .pdf (optional)", type=["txt","docx","pdf"])
    lens_name = st.text_input("Lens name", value="My Lens")
    if st.button("Add lens"):
        text = ""
        try:
            if up:
                if up.name.lower().endswith(".txt"):
                    text = up.read().decode("utf-8","ignore")
                elif up.name.lower().endswith(".docx") and docx:
                    d = docx.Document(up); text = "\n".join(p.text for p in d.paragraphs)
                elif up.name.lower().endswith(".pdf") and PyPDF2:
                    pdf = PyPDF2.PdfReader(up)
                    text = "\n".join((page.extract_text() or "") for page in pdf.pages)
        except Exception:
            text = ""

        # Simple heuristics → lens buckets
        buckets = {"collapse":[],"recursion":[],"emergence":[],"neutral":[]}
        if text.strip():
            lines = [l.strip() for l in text.replace("\r","").split("\n") if len(l.strip())>8]
            for ln in lines:
                low = ln.lower()
                if any(k in low for k in ["release","end","quit","close","let go"]): buckets["collapse"].append(ln)
                elif any(k in low for k in ["repeat","again","habit","loop","daily","consistency"]): buckets["recursion"].append(ln)
                elif any(k in low for k in ["begin","start","spark","future","transform","new"]): buckets["emergence"].append(ln)
                else:
                    buckets["neutral"].append(ln)
        else:
            # empty lens is fine — uses core phrases
            pass

        valid = strict_lens_schema(buckets)
        if valid:
            lens_put(pid, lens_name, valid)
            st.success("Lens saved.")
        else:
            st.error("Invalid lens data.")

    st.markdown("---")
    # Active lenses
    all_lenses_dict = get_all_lenses_dict(pid)
    LENS_NAMES = list(all_lenses_dict.keys())

    colA,colB,colC = st.columns([1,1,2])
    with colA:
        sel1 = st.selectbox("Primary lens", LENS_NAMES, index=LENS_NAMES.index(settings_get(pid,"lens_primary","Core")) if settings_get(pid,"lens_primary","Core") in LENS_NAMES else 0)
        settings_set(pid,"lens_primary",sel1)
    with colB:
        use2 = st.checkbox("Use secondary lens", value=(settings_get(pid,"lens_use_secondary","0")=="1"))
        settings_set(pid,"lens_use_secondary","1" if use2 else "0")
        if use2:
            sel2 = st.selectbox("Secondary lens", LENS_NAMES, index=LENS_NAMES.index(settings_get(pid,"lens_secondary","Core")) if settings_get(pid,"lens_secondary","Core") in LENS_NAMES else 0)
            settings_set(pid,"lens_secondary",sel2)
    with colC:
        blend = st.slider("Blend weight (secondary influence)", 0.0, 1.0, float(settings_get(pid,"lens_blend","0.0")) if use2 else 0.0, 0.05, disabled=not use2)
        settings_set(pid,"lens_blend",blend)

    # Preview
    ctx = {"goal": settings_get(pid,"goal","")}
    prev = smart_lens_line(pid, "recursion", ctx, sel1, (sel2 if use2 else None), blend)
    st.markdown(f"**Preview line:** {prev or '—'}")

# =============
# LENS MEMORY TAB
# =============
elif tab == "Lens Memory":
    st.header("Lens Memory")
    rec = lens_memory_recent(pid, 50)
    if not rec:
        st.caption("No lines yet. Use Forecast or Interventions to see narration appear here.")
    else:
        for r in rec:
            st.markdown(f"`{r['at']}` • **{r['lens_name']}** / *{r['kind']}*  \n> {r['phrase']}")

# =============
# EXPORT / IMPORT TAB
# =============
elif tab == "Export/Import":
    st.header("Export / Import (profile-scoped)")
    if st.button("Export"):
        dump = {
            "profile": sel,
            "settings": fetch("SELECT key,val FROM settings WHERE profile_id=?", (pid,)),
            "days": fetch("SELECT * FROM days WHERE profile_id=?", (pid,)),
            "loops": fetch("SELECT * FROM loops WHERE profile_id=?", (pid,)),
            "custom_loops": fetch("SELECT * FROM custom_loops WHERE profile_id=?", (pid,)),
            "lens": fetch("SELECT name,data FROM lens WHERE profile_id=?", (pid,)),
            "lens_memory": fetch("SELECT at,lens_name,kind,phrase,ctx FROM lens_memory WHERE profile_id=?", (pid,)),
            "interventions_log": fetch("SELECT at,title,accepted,helped FROM interventions_log WHERE profile_id=?", (pid,)),
            "interventions_log_ctx": fetch("SELECT at,title,ctx,reward FROM interventions_log_ctx WHERE profile_id=?", (pid,)),
            "forecast_feedback": fetch("SELECT at,accurate FROM forecast_feedback WHERE profile_id=?", (pid,))
        }
        st.download_button("Download JSON", data=json.dumps(dump, indent=2).encode("utf-8"), file_name=f"timesculpt_{sel}.json", mime="application/json")

    st.markdown("---")
    up = st.file_uploader("Import JSON (replaces conflicting rows)", type=["json"])
    if up and st.button("Import now"):
        try:
            data = json.loads(up.read().decode("utf-8"))
            # minimal safety
            for row in data.get("settings", []):
                settings_set(pid, row["key"], row["val"])
            for row in data.get("days", []):
                run("INSERT OR REPLACE INTO days(profile_id,d,note,state,focus,energy,progress) VALUES(?,?,?,?,?,?,?)",
                    (pid,row["d"],row["note"],row["state"],row["focus"],row["energy"],row["progress"]))
            for row in data.get("loops", []):
                run("INSERT OR REPLACE INTO loops(profile_id,d,name,amount,unit) VALUES(?,?,?,?,?)",
                    (pid,row["d"],row["name"],row["amount"],row.get("unit","minutes")))
            for row in data.get("custom_loops", []):
                custom_loop_add(pid,row["name"],row["category"],row["polarity"],row.get("unit","minutes"),row.get("rate_label","weight"),row.get("rate_value",1.0))
            for row in data.get("lens", []):
                d = strict_lens_schema(json.loads(row["data"])) if isinstance(row["data"], (str,bytes)) else strict_lens_schema(row["data"])
                if d: lens_put(pid,row["name"],d)
            for row in data.get("lens_memory", []):
                log_lens_memory(pid,row["lens_name"],row["kind"],row["phrase"],json.loads(row.get("ctx","{}")))
            for row in data.get("interventions_log", []):
                run("INSERT INTO interventions_log(profile_id,at,title,accepted,helped) VALUES(?,?,?,?,?)",
                    (pid,row["at"],row["title"],row.get("accepted",0),row.get("helped",None)))
            for row in data.get("interventions_log_ctx", []):
                run("INSERT INTO interventions_log_ctx(profile_id,at,title,ctx,reward) VALUES(?,?,?, ?,?)",
                    (pid,row["at"],row["title"],json.dumps(row.get("ctx",[])),row.get("reward",None)))
            for row in data.get("forecast_feedback", []):
                run("INSERT INTO forecast_feedback(profile_id,at,accurate) VALUES(?,?,?)",
                    (pid,row["at"],row.get("accurate",1)))
            st.success("Import complete.")
        except Exception as e:
            st.error(f"Import failed: {e}")

# =============
# HELP TAB (last)
# =============
elif tab == "Help":
    st.header("How to use TimeSculpt")
    st.markdown("""
1) **Input** → Log your day with units that make sense to you.  
   - The system converts everything to **effective minutes** for scoring.
   - Add your **Goal**; suggestions and narration bias toward it.
   - Use **Undo last commit** if you mis-logged.

2) **Forecast** → See the next 30 days as probabilities (Focused / Mixed / Drift).  
   - The model **learns transitions** from your history (Dirichlet calibration).  
   - Mark "plausible/off" to help it calibrate.  
   - Read the **Brief** for one clear takeaway (AI optional).

3) **Interventions** → Smallest honest moves ranked by expected impact.  
   - **Apply** a move; later mark **Helped?** → the **bandit** learns which moves work for *you*.  
   - See **Proven for you** over 30/90 days.

4) **Diagnostics** → Find your **Force (+)** and **Drift (−)** loops, plus 14→14 changes.

5) **Lens** → Upload passages to shape the app’s voice.  
   - You can blend a secondary lens; the system avoids recent repeats and favors lines aligned to your goal.

6) **Lens Memory** → Every line the app spoke, saved.

7) **Export/Import** → Your data, per profile, portable.

**Privacy:** All data is local (SQLite). AI calls happen only if you toggle **AI narration** on and you have `OPENAI_API_KEY` set in your environment.
""")
